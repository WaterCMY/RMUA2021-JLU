{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PulVw_da4GML"
      },
      "source": [
        "# HW3 - EE599 Systems for Machine Learning, Fall 2023\n",
        "University of Southern California\n",
        "\n",
        "Instructors: Arash Saifhashemi, Murali Annavaram\n",
        "\n",
        "In this homework assignment, we will ask you to use various methods to implement convolution operation, and then measure and analyze the performance of each method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG26EClp5nEq"
      },
      "source": [
        "## Prepare your Google Drive\n",
        "- Download `ML_Systems_HW3` zip file from GitHub and unzip the it (you may need to rename the unzipped folder).\n",
        "- Upload unzipped folder to ``My Drive`` in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02VQPV6q4Cav",
        "outputId": "6aaec690-4eb3-4bbd-fc4a-dbc9c13170fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/ML_Systems_HW3/src')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITQeV_DO755_"
      },
      "source": [
        "## Verify that you are in the correct working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2Y1rLNv7434",
        "outputId": "8bf06716-aca0-446e-d7da-a6135ad01536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML_Systems_HW3/src\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dioEAKJm6BUN"
      },
      "source": [
        "## Create a folder named `build` under `ML_Systems_HW3/src`, which will be used to store executable files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XemyfZFZ6BUN",
        "outputId": "837c64a4-bcbe-4a1e-90d4-02d44d10888d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘build’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcEAwSWG6wSi",
        "outputId": "2d8763ad-f27c-47a4-8e03-2d1765247e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled q1_conv2d_naive.cc successfully!\n",
            "Compiled q2_conv2d_toeplitz.cc successfully!\n",
            "Compiled q3_conv2d_toeplitz_transB.cc successfully!\n",
            "\u001b[01m\u001b[Kq4_conv2d_toeplitz_avx.cc:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kq4_conv2d_toeplitz_avx.cc:102:21:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput\u001b[m\u001b[K’ was not declared in this scope\n",
            "  102 |   printSumOfOutputs(\u001b[01;31m\u001b[Koutput\u001b[m\u001b[K, output_c * output_p * output_q);\n",
            "      |                     \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq4_conv2d_toeplitz_avx.cc:102:29:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_c\u001b[m\u001b[K’ was not declared in this scope\n",
            "  102 |   printSumOfOutputs(output, \u001b[01;31m\u001b[Koutput_c\u001b[m\u001b[K * output_p * output_q);\n",
            "      |                             \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq4_conv2d_toeplitz_avx.cc:102:40:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_p\u001b[m\u001b[K’ was not declared in this scope\n",
            "  102 |   printSumOfOutputs(output, output_c * \u001b[01;31m\u001b[Koutput_p\u001b[m\u001b[K * output_q);\n",
            "      |                                        \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq4_conv2d_toeplitz_avx.cc:102:51:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_q\u001b[m\u001b[K’ was not declared in this scope\n",
            "  102 |   printSumOfOutputs(output, output_c * output_p * \u001b[01;31m\u001b[Koutput_q\u001b[m\u001b[K);\n",
            "      |                                                   \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq4_conv2d_toeplitz_avx.cc:108:31:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Ktemp_output\u001b[m\u001b[K’ was not declared in this scope\n",
            "  108 |   deallocateAlignedFloatArray(\u001b[01;31m\u001b[Ktemp_output\u001b[m\u001b[K);\n",
            "      |                               \u001b[01;31m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "Error compiling q4_conv2d_toeplitz_avx.cc!\n",
            "\u001b[01m\u001b[Kq5_conv2d_toeplitz_avx_openmp.cc:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kq5_conv2d_toeplitz_avx_openmp.cc:104:21:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput\u001b[m\u001b[K’ was not declared in this scope\n",
            "  104 |   printSumOfOutputs(\u001b[01;31m\u001b[Koutput\u001b[m\u001b[K, output_c * output_p * output_q);\n",
            "      |                     \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq5_conv2d_toeplitz_avx_openmp.cc:104:29:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_c\u001b[m\u001b[K’ was not declared in this scope\n",
            "  104 |   printSumOfOutputs(output, \u001b[01;31m\u001b[Koutput_c\u001b[m\u001b[K * output_p * output_q);\n",
            "      |                             \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq5_conv2d_toeplitz_avx_openmp.cc:104:40:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_p\u001b[m\u001b[K’ was not declared in this scope\n",
            "  104 |   printSumOfOutputs(output, output_c * \u001b[01;31m\u001b[Koutput_p\u001b[m\u001b[K * output_q);\n",
            "      |                                        \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq5_conv2d_toeplitz_avx_openmp.cc:104:51:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_q\u001b[m\u001b[K’ was not declared in this scope\n",
            "  104 |   printSumOfOutputs(output, output_c * output_p * \u001b[01;31m\u001b[Koutput_q\u001b[m\u001b[K);\n",
            "      |                                                   \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq5_conv2d_toeplitz_avx_openmp.cc:110:31:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Ktemp_output\u001b[m\u001b[K’ was not declared in this scope\n",
            "  110 |   deallocateAlignedFloatArray(\u001b[01;31m\u001b[Ktemp_output\u001b[m\u001b[K);\n",
            "      |                               \u001b[01;31m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "Error compiling q5_conv2d_toeplitz_avx_openmp.cc!\n",
            "\u001b[01m\u001b[Kq6_conv2d_toeplitz_blas.cc:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kq6_conv2d_toeplitz_blas.cc:101:21:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput\u001b[m\u001b[K’ was not declared in this scope\n",
            "  101 |   printSumOfOutputs(\u001b[01;31m\u001b[Koutput\u001b[m\u001b[K, output_c * output_p * output_q);\n",
            "      |                     \u001b[01;31m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq6_conv2d_toeplitz_blas.cc:101:29:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_c\u001b[m\u001b[K’ was not declared in this scope\n",
            "  101 |   printSumOfOutputs(output, \u001b[01;31m\u001b[Koutput_c\u001b[m\u001b[K * output_p * output_q);\n",
            "      |                             \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq6_conv2d_toeplitz_blas.cc:101:40:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_p\u001b[m\u001b[K’ was not declared in this scope\n",
            "  101 |   printSumOfOutputs(output, output_c * \u001b[01;31m\u001b[Koutput_p\u001b[m\u001b[K * output_q);\n",
            "      |                                        \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq6_conv2d_toeplitz_blas.cc:101:51:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Koutput_q\u001b[m\u001b[K’ was not declared in this scope\n",
            "  101 |   printSumOfOutputs(output, output_c * output_p * \u001b[01;31m\u001b[Koutput_q\u001b[m\u001b[K);\n",
            "      |                                                   \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kq6_conv2d_toeplitz_blas.cc:107:31:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[Ktemp_output\u001b[m\u001b[K’ was not declared in this scope\n",
            "  107 |   deallocateAlignedFloatArray(\u001b[01;31m\u001b[Ktemp_output\u001b[m\u001b[K);\n",
            "      |                               \u001b[01;31m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "Error compiling q6_conv2d_toeplitz_blas.cc!\n",
            "All files compiled successfully!\n"
          ]
        }
      ],
      "source": [
        "!bash compile.csh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0k8aaYu6zXv",
        "outputId": "ed518e77-ffb2-4e2d-8814-26558e04fecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running q1_conv2d_naive ...\n",
            "Virtual Memory (KB): 16716\n",
            "temp: 0\n",
            "Time taken by function: 20809 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q2_conv2d_toeplitz ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 14076 milliseconds\n",
            "Sum of all outputs: 47457292288\n",
            "-------------------------------------------\n",
            "Running q3_conv2d_toeplitz_transB ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 12485 milliseconds\n",
            "Sum of all outputs: 47457292288\n",
            "-------------------------------------------\n",
            "Running q4_conv2d_toeplitz_avx ...\n",
            "run.csh: line 16: ./build/q4_conv2d_toeplitz_avx: No such file or directory\n",
            "-------------------------------------------\n",
            "Running q5_conv2d_toeplitz_avx_openmp ...\n",
            "run.csh: line 16: ./build/q5_conv2d_toeplitz_avx_openmp: No such file or directory\n",
            "-------------------------------------------\n",
            "Running q6_conv2d_toeplitz_blas ...\n",
            "run.csh: line 16: ./build/q6_conv2d_toeplitz_blas: No such file or directory\n",
            "-------------------------------------------\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "!bash run.csh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Jeis0Q6BUO"
      },
      "source": [
        "## Compile and run your code:\n",
        "* To compile your C++ code, run command `!bash compile.csh`\n",
        "* To run your executable code, run command `!bash run.csh`\n",
        "* Check those csh files and modify accordingly when testing your code.\n",
        "* You can write and test your code on your local machine but make sure you can compile and run them on Colab. Also you should report the performance measured from Colab enverionment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNu5C22Q6BUO"
      },
      "source": [
        "## Write code and answer all questions in this notebook.\n",
        "Note that to measure the performance of each code, we want you to flush your cache. All the template files provide code that flush caches, but we need you to find the cache size of your system. Use the command below to display information about your CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OzO0J8J6BUO",
        "outputId": "8b6bd847-8069-44e0-b8c4-f63cc1e00981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:            x86_64\n",
            "  CPU op-mode(s):        32-bit, 64-bit\n",
            "  Address sizes:         46 bits physical, 48 bits virtual\n",
            "  Byte Order:            Little Endian\n",
            "CPU(s):                  2\n",
            "  On-line CPU(s) list:   0,1\n",
            "Vendor ID:               GenuineIntel\n",
            "  Model name:            Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:          6\n",
            "    Model:               79\n",
            "    Thread(s) per core:  2\n",
            "    Core(s) per socket:  1\n",
            "    Socket(s):           1\n",
            "    Stepping:            0\n",
            "    BogoMIPS:            4399.99\n",
            "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mc\n",
            "                         a cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscal\n",
            "                         l nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopo\n",
            "                         logy nonstop_tsc cpuid tsc_known_freq pni pclmulqdq sss\n",
            "                         e3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes \n",
            "                         xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefe\n",
            "                         tch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_ad\n",
            "                         just bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed ad\n",
            "                         x smap xsaveopt arat md_clear arch_capabilities\n",
            "Virtualization features: \n",
            "  Hypervisor vendor:     KVM\n",
            "  Virtualization type:   full\n",
            "Caches (sum of all):     \n",
            "  L1d:                   32 KiB (1 instance)\n",
            "  L1i:                   32 KiB (1 instance)\n",
            "  L2:                    256 KiB (1 instance)\n",
            "  L3:                    55 MiB (1 instance)\n",
            "NUMA:                    \n",
            "  NUMA node(s):          1\n",
            "  NUMA node0 CPU(s):     0,1\n",
            "Vulnerabilities:         \n",
            "  Itlb multihit:         Not affected\n",
            "  L1tf:                  Mitigation; PTE Inversion\n",
            "  Mds:                   Vulnerable; SMT Host state unknown\n",
            "  Meltdown:              Vulnerable\n",
            "  Mmio stale data:       Vulnerable\n",
            "  Retbleed:              Vulnerable\n",
            "  Spec store bypass:     Vulnerable\n",
            "  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy ba\n",
            "                         rriers only; no swapgs barriers\n",
            "  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBR\n",
            "                         S: Not affected\n",
            "  Srbds:                 Not affected\n",
            "  Tsx async abort:       Vulnerable\n"
          ]
        }
      ],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hk0XSjP9_n3"
      },
      "source": [
        "## Q1\n",
        "Implement 2D Convolution in the ``q1_conv2d_naive.cc`` using nested for loops. Assume batch size = 1, no padding and stride = 1. Check `util.h` file and understand what each function does. Use the micro `INDEX_4D_TO_1D` to help convert 4d index to 1d index. Measure and report runtime  (in milliseconds) and memory usage (in KB). Manually calculate memory usage and report. Does your calculation match with the measurement?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16706KB by manually calculating.\n",
        "No, it doesn't match. The difference is 10KB."
      ],
      "metadata": {
        "id": "iqiiWFPl_FyE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBXb2fV_-YO7"
      },
      "source": [
        "## Q2\n",
        "Use Img2col algorithm to convert the input matrix and kernel matrix to toeplitz form in file ``q2_conv2d_toeplitz.cc``. Interpret input toeplitz matrix and kernel toeplitz matrix as 2d matrix, and store both of them in row major. Use nested for loops to perform matrix multiplication in `matMul` function and call it in `main` function . There is another micro `INDEX_2D_TO_1D` that helps convert 2d index to 1d index. Measure and report runtime and memory usage. Manually calculate memory usage and report. Does your calculation match with the measurement?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "79956KB by manually calculating. No, it doesn't match. The difference is 8KB."
      ],
      "metadata": {
        "id": "723AWGlD6T4J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjmFTWrK_FJU"
      },
      "source": [
        "## Q3\n",
        "For `q3_conv2d_toeplitz_tranB.cc`, repeat procedures in Q2, but store kernel toeplitz matrix in column major and modify `matMul` function accordingly. Measure and report the runtime and memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5SaluD5_ydp"
      },
      "source": [
        "## Q4\n",
        "For ``q4_conv2d_toeplitz_avx.cc``, use Intel AVX (Advanced Vector Extensions) instruction set to perform matmul operation. Intel AVX instructions are Single Instruction Multiple Data (SIMD) instructions that can process 8 floating-point operands in a single instruction. Store input toeplitz matrix in row major and kernel toeplitz matrix in column major. An example of using Intel AVX is given in file ``examples/example_vectorsum_simd.cc``. Measure and report runtime and memory usage.\n",
        "\n",
        "Hint 1: Use `_mm256_add_ps` and `_mm256_mul_ps` instructions.\n",
        "\n",
        "Hint 2: If a vector is not divisible by 8, the remaining elements in the vector should not be processed by SIMD instruction. Instead, use normal scalar operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqRyp0x8A99J"
      },
      "source": [
        "## Q5\n",
        "\n",
        "### Part 1\n",
        "In file ``q5_conv2d_toeplitz_avx_openmp.cc``, futher optimize the AVX matmul operation using ``OpenMP`` library, which enables multi-threaded parallel computing automatically through a simple and flexible interface. An example of using ``OpenMP`` is given in file ``examples/example_vectorsum_simd_omd.cc``. Run the code with different number of threads. Measure and report the runtime for number of threads = [2, 4, 8].\n",
        "\n",
        "\n",
        "### Part 2 (Optional - No Credit)\n",
        "\n",
        "In file ``q5_optional_conv2d_toeplitz_avx_multi_thread.cc``, instead of using `OpenMP`, use the C++ standard `<thread>` library to implement multi-threaded AVX matmul operation. You can refer to [this video](https://youtu.be/3aqxaZsvn80?si=1QEE580e2vLmrqPO) to learn about multi threading in C++.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW-_R8gm6BUQ"
      },
      "source": [
        "## Q6\n",
        "\n",
        "In file ``q6_conv2d_toeplitz_blas.cc``, use `BLAS` library to implement matmul operation. You can decide the storage format for input and kernel toeplitz matrices, and make sure you set input arguments of `cblas_sgemm` accordingly. An example is given in file ``examples/example_matmul_blas.cc``. Search online document of `cblas_sgemm` API if you are unclear about the mearning of each of its input argument. Follow the example and and finish your own code. Measure and report runtime and memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVxmA8VB2n5"
      },
      "source": [
        "## Q7  \n",
        "\n",
        "### Part 1\n",
        "\n",
        "\n",
        "Analyze the performance differences between Q1-Q6. Explain what constitutes the performance difference between each implementations and why `BLAS` library is super fast.\n",
        "\n",
        "### Part 2: Using Google Benchmark (Optional - No Credit)\n",
        "As an optional practice, you can measure the runtime of each matrix calculation method more accurately using Google benchmark.\n",
        "\n",
        "A better way to measure performance of a funcion in C++ is to use Google Benchmark. You can refer to [this video](https://youtu.be/9VKR8u9odrA?si=xSInuzT5uMBOKAbP) to familiarize yourself with this package.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m7NCnmR6BUQ"
      },
      "source": [
        "## Upload files to GitHub\n",
        "Make sure upload your final C++ code and this IPython notebook to GitHub Repo either mannully or through git commands."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}